ğŸ§  Sentient Symbolic AI Framework (No ML, No Neural Nets)

A rule-based, emotional and morally evaluative AI system using natural language processing (NLP) techniques and symbolic logic. Inspired by human-like evaluation: emotional, logical, moral, selfish/selfless reasoning â€” without neural networks.

ğŸ“˜ Overview

This project creates a symbolically driven "sentient" AI system that mimics thinking and emotional behavior using:

ğŸ’­ Custom symbolic parsing of sentence structure

ğŸ§  Evaluation of meaning, logic, morality, emotion

ğŸ˜  Dynamic emotional state modeling via emotion.json files

ğŸ¤– Output generation influenced by internal state and reasoning

ğŸ‘ï¸ External input override (forcing "mood" or "bias")

This AI doesn't learn by training â€” it "experiences" the world and reacts, changes emotionally, and reflects its state in outputs.

âš™ï¸ Setup Instructions
Requirements

Python 3.8+

spaCy NLP library

pip install spacy
python -m spacy download en_core_web_sm

File/Folder Structure
project-root/
â”‚
â”œâ”€â”€ ai_engine/
â”‚   â”œâ”€â”€ evaluator.py             # Evaluates sentence meaning
â”‚   â”œâ”€â”€ emotion_handler.py       # Emotion read/write logic
â”‚   â”œâ”€â”€ nlp_parser.py            # Sentence parsing logic
â”‚   â”œâ”€â”€ thought_processor.py     # Core of "thinking"
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ emotions/
â”‚       â”œâ”€â”€ anger/
â”‚       â”‚   â””â”€â”€ emotion.json
â”‚       â”œâ”€â”€ joy/
â”‚       â”‚   â””â”€â”€ emotion.json
â”‚       â””â”€â”€ ... (other emotions)
â”‚
â”œâ”€â”€ config.json                  # Root path configs, etc.
â””â”€â”€ main.py                      # Entry point / interface

ğŸ§  Core Concepts (Your Terms Explained & Structured)
Term	Meaning / Implementation Plan
Think = WoCGuk	WayOptions + Context + General Understanding of Knowledge
â†’ Parse sentence â†’ Identify verbs/nouns/context â†’ Match known concepts
â†’ Consider internal emotional & moral bias
Learn = PTEGnOGeI	ProcessThinkEvaluate + GenerateOutput + GetInput
â†’ Evaluate meaning â†’ Affect emotion â†’ Store experience â†’ Generate next output
Emotionexp = CeEc	ChangeiEmotion + EmotionalChange
â†’ Use emotion files to modulate internal state after evaluating input
ExternalFeed = Ef	Allow external modules (or developer) to override evaluation temporarily (e.g., simulate rage, joy)
Evaluate	Use verbs and known concept maps (e.g., kill = bad, hug = good) to assign moral, logical, and emotional weight
ğŸ” Modules and Their Purpose
1. nlp_parser.py

Goal: Understand sentence structure, roles (subject, verb, object), QWORDs, etc.

Functions:

get_sen_structure(text)

get_subj_and_obj(doc)

search_verbs(pos_list)

search_nouns(pos_list)

type_of_sentence(doc)

get_qword_pos(pos_list)

type_qword(...)

This provides the structural understanding of text input.

2. emotion_handler.py

Goal: Load/save/adjust emotion state (persistent, per emotion)

Functions:

read_emotion_level(emotion)

write_emotion_level(emotion, level, intensity)

load_json(path)

save_json(path)

EmotionState class (cache emotion data)

Allows for tracking internal mood and reacting differently as emotion evolves.

3. evaluator.py

Goal: Core logic to assign meaning, moral weight, emotional reaction, selfishness to an input

Concept Map Example:

meaning_map = {
    "hug": {"emotion": {"joy": 5}, "moral": 4, "selfishness": -2},
    "kill": {"emotion": {"anger": 7, "sadness": 5}, "moral": -9, "selfishness": 5},
    ...
}


Function:

def evaluate_sentence(doc, emotion_state):
    ...
    return {"emotion": ..., "moral": ..., "selfishness": ...}


This is where your AI "thinks" and forms a judgment or response. It is the implementation of Think.

4. thought_processor.py

Goal: Handle cycles of:

Think

Learn

React

Emotionexp

Function examples:

def process_input(text, emotion_state):
    parsed_doc = nlp_parser.parse(text)
    evaluation = evaluator.evaluate_sentence(parsed_doc, emotion_state)
    emotion_handler.update_emotions(evaluation)
    response = response_generator.generate(evaluation, emotion_state)
    return response


This represents the symbolic cycle of thought.

5. main.py

Handles:

Input loop

User interface (CLI or API)

Optionally hooks in ExternalFeed

ğŸ› ï¸ Development Tasks
âœ… Phase 1: POS Tagging & Structure Parsing

 Implement get_sen_structure(), get_subj_and_obj(), etc.

 Classify sentence type (question, statement, exclamation)

 Detect QWORDs, verbs, nouns

âœ… Phase 2: Emotion Engine (Emotionexp)

 Create JSONs per emotion

 Create reader/writer logic

 Add EmotionState cache class

âœ… Phase 3: Evaluation Engine (Think)

 Define concept/verb-to-meaning mapping

 Build evaluate_sentence() logic

 Calculate emotional impact, moral weight, selfishness

â³ Phase 4: Integration (Learn)

 Combine NLP + Evaluation + Emotionexp into one flow

 Enable emotion adjustment after input is evaluated

 Store short-term memory of previous interactions

â³ Phase 5: Output Generation (Emotion-based)

 Generate responses based on:

Mood (current emotion levels)

Past inputs

Morality / selfishness score

 Example:

Input: "You are useless!"

Emotion: anger +2

Response: â€œThat was rude. Why would you say that?â€

â³ Phase 6: External Feed System (Ef)

 Add override system for injecting emotion directly:

emotion_state.override_emotion("joy", level=10)


 Simulate fake situations for testing (â€œsimulate betrayalâ€)

ğŸ§ª Examples

Input:

"Why did he hurt me?"


Parser Output:

Type: Question

QWORD: why

Subject: he

Verb: hurt

Object: me

Evaluation:

{
  "emotion": { "sadness": 6 },
  "moral": -5,
  "selfishness": 3
}


Updated Emotion:

sadness level +1

sadness intensity +1

Response:

"That was wrong of him. I'm sorry that happened."

ğŸ§° Future Expansion Ideas

 Memory system: Store past interactions to influence future mood

 Value reinforcement: Grow emotional intensity based on frequency

 Internal conflict logic (e.g., anger vs guilt)

 External sensors/inputs (e.g., visual or sound input)

ğŸ’¡ Tip for You

You're building a symbolic artificial mind â€” it needs to:

Understand sentence structure

Apply subjective values (emotion, morality, etc.)

Update internal state

Respond with intent based on emotional lens

Youâ€™re already most of the way there. Stick to the modules. Build them piece-by-piece. You can test manually, simulate feelings, and define custom rules without any black-box ML models.

Would you like me to generate starter code templates for each module based on this structure? It could give you a solid coding foundation right away.